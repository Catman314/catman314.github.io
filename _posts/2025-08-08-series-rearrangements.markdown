---
title: Rearrangement of Infinite Series
author: Catman
layout: post
long: true
---

> As I was reading Abbott's *Understanding Analysis*, I came upon the theorem stating that if a series converges absolutely, then any rearrangement of the series converges to the same value. I wanted to see at an intuitive level why absolute convergence is the key here.

### Rearranged Sums are Weird

Check out this example from Abbott's *Understanding Analysis* Section 2.1.

$$
\begin{align*}
  s &= 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \frac{1}{5} - \frac{1}{6} + \frac{1}{7} - \frac{1}{8} + \frac{1}{9} - \dots \\
  t &= 1 + \frac{1}{3} - \frac{1}{2} + \frac{1}{5} + \frac{1}{7} - \frac{1}{4} + \frac{1}{9} + \frac{1}{11} - \frac{1}{6} + \dots.
\end{align*}
$$

These infinite sums both have the same terms overall; the second sum is generated by alternating between taking 2 positive terms and 1 negative term from the first sum.

It turns out that $s = \log 2$ and $t = 1.5\log 2$ (the specifics are irrelevant to this post.) These sums are not equal even though they consist of the same terms. This is no trick; infinite sums are just weird sometimes!

#### The "Initial" and "Extra" Terms

Look at, say, the first 20 terms of this rearranged series, and with the indices sorted. You can check that this becomes

$$
\begin{align*}
  \underbrace{1 - \frac{1}{2} + \dots + \frac{1}{13}}_{\text{Initial Terms}} + \underbrace{\frac{1}{15} + \frac{1}{17} + \frac{1}{19} + \frac{1}{21} + \frac{1}{23} + \frac{1}{25} + \frac{1}{27}}_{\text{Extra Terms}}.
\end{align*}
$$

Notice that this rearranged sum contains every term from $1$ to $\frac{1}{13}$. I will call these the *initial terms*. If we keep adding more and more of the rearranged series, the number of initial terms will get arbitrarily large. Note that the sum of these initial terms gets arbitrarily close to $s$ as more are added.

But there are also *extra terms* outside those initial terms, and these extras can cause problems for us. In our particular example, the extra terms *don't* go to zero over time. It is these extra terms that change the rearranged sum.

### But I Wanna Rearrange :(

We've seen that when summing the rearranged series, there is a split between *initial terms* and *extra terms*. The initial terms are very well behaved, approaching $s$ over time, but the extra terms can be harder to predict since they could be anywhere after the initial terms. We want to somehow impose a restriction on the sequence which makes the extra terms negligible over time. If that were true, then the rearranged series would become closer and closer to the initial terms over time. Since the initial terms get closer and closer to $s$, so does the rearranged series.

However, this is clearly not the case, as we've seen a rearranged series where the extra terms don't vanish over time!

#### Conditional Convergence

One way to look at the problem, is that it's a kind of "paradox" involving infinite distance being traveled. By distance, I mean the *absolute values* of the series. Returning to our example, this sum would be

$$1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \dots$$

This series actually gets arbitrarily large over time, although this happens at a very slow (logarithmic) rate. When this unbounded distance occurs, we say the series is *conditionally convergent*.

Now suppose we sum a huge number of initial terms $1 - \frac{1}{2} + \dots + \frac{1}{N}$ in the rearranged series. We can certainly get very close to the sum, but there is still an infinite amount of distance left to be traveled!

This is where the extra terms can offset the rearranged sum. If we choose them right, then we can take full advantage of the infinite distance remaining. For example, the positive terms we chose would ordinarily be canceled by the negative terms, but the total distance travelled is pretty big still. If we don't include negative terms as extras, the positive terms are given more power to offset the sum.

#### Absolute Convergence

Let's take a look at another infinite series,

$$1 - \frac{1}{4} + \frac{1}{9} - \frac{1}{16} + \frac{1}{25} - \dots,$$

and we will rearrange it the same way as in the first example. This time, the total distance traveled,

$$1 + \frac{1}{4} + \frac{1}{9} + \frac{1}{16} + \frac{1}{25} + \dots,$$

is finite! In fact, it is $\frac{\pi^2}{6}$ (IRRELEVANT). Let's repeat the same process as before, getting the initial terms $1 - \frac{1}{4} + \dots + \frac{1}{N}$ in the rearranged series. In the case of absolute convergence, as we add more and more initial terms, the distance remaining eventually gets tiny because the total distance is finite.

Now the extra terms can only cover this tiny distance! Over time, the extra terms approach 0, so the rearranged sum is left virtually unchanged by the extra terms. Since the initial terms get closer and closer to the original sum $s$, so does the rearranged sum.

---

To summarize, the distance covered by the initial terms in an absolutely convergent series chops away at the remaining distance allocated to the extra terms. In a conditionally convergent series, this is not the case because the initial terms are trying to chop away only finitely at an infinitely large distance. There is always plenty of distance remaining for the extra terms to shift around the sum.

### The Formal Proof

> **Theorem**: If a series converges *absolutely*, then every rearrangement has the same sum.

*Proof.* Let $(a_n)$ be a sequence who's sum $s = \sum_{k=1}^\infty a_k$ converges absolutely. Let $\sigma$ be a permutation of the natural number (the indices).

To prove the statement, fix $\varepsilon > 0$. We want to show that for all $n$ beyond some $N$,

$$\left\vert \sum_{k=1}^{n} a_{\sigma(k)} - s\right\vert < \varepsilon$$

With the idea of initial and extra terms in mind, we define $M$ so that
* We have
  $\left|\sum_{k=1}^M a_k - s\right| < \varepsilon/2$.
* For all $n > m \ge M$ we have
  $\sum_{k=M+1}^\infty |a_k| < \varepsilon/2$. This is possible by absolute convergence.

Now we need to choose $N$ such that $\sigma(1),\sigma(2),\dots,\sigma(N)$ contains all of the indices $1,2,\dots,M$. We define

$$N = \max\{\sigma^{-1}(1),\sigma^{-1}(2),\dots,\sigma^{-1}(n)\}$$

to ensure this. For any $n\ge N$, the set $\sigma(1),\sigma(2),\dots,\sigma(n)$ consists of the initial indices $1,2,\dots,M$, as well as the extra indices which I'll call $n_1,n_2,\dots,n_j$. The rearranged sum is then split into

$$\sum_{k=1}^n a_{\sigma(k)} = \sum_{k=1}^M a_{k} + \sum_{k=1}^j a_{n_k}.$$

Then we have

$$
\begin{align*}
  \left|\sum_{k=1}^M a_{k} + \sum_{k=1}^j a_{n_k} - s\right| &\le \left|\sum_{k=1}^M a_{k} - s\right| + \sum_{k=M+1}^\infty |a_k| \\
  &< \varepsilon/2 + \varepsilon/2 = \varepsilon.
\end{align*}
$$


### Further Ideas

* One alternative approach I came up with is, instead of restricting the sequence, we could restrict the permutation. 
  * This could be done in such a way that the number of extra terms is limited.
  * Perhaps there is a middleground where we add less restrictive rules for both the sequence and the rearrangement.

* The topic of rearrangements sparked an interest in a generalization of sequences and sums in which terms are indexed by ordinal numbers.
  * My idea is to show that more general types of rearrangements give similar results (such as swapping double sums).